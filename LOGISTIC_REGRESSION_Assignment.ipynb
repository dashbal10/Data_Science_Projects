{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "799353e8-2e79-4092-a18c-5acce8be4ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "#1. Data Exploration\n",
    "import pandas as pd\n",
    "\n",
    "# Load your datasets\n",
    "train_df = pd.read_csv('Titanic_train.csv')\n",
    "test_df = pd.read_csv('titanic_test.csv')\n",
    "\n",
    "# View the first few rows\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbd66e95-bb63-4626-9f0d-bef938d6c1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#2. Explore the Data\n",
    "\n",
    "#Check for missing values, data types, and distributions:\n",
    "print(train_df.info())\n",
    "print(train_df.describe())\n",
    "print(train_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf555199-fc34-4da0-b294-341a04b01603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\APPY\\AppData\\Local\\Temp\\ipykernel_7752\\4245419610.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df['Age'].fillna(train_df['Age'].median(), inplace=True)\n",
      "C:\\Users\\APPY\\AppData\\Local\\Temp\\ipykernel_7752\\4245419610.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['Age'].fillna(test_df['Age'].median(), inplace=True)\n",
      "C:\\Users\\APPY\\AppData\\Local\\Temp\\ipykernel_7752\\4245419610.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['Fare'].fillna(test_df['Fare'].median(), inplace=True)\n",
      "C:\\Users\\APPY\\AppData\\Local\\Temp\\ipykernel_7752\\4245419610.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#3: Preprocess the Data\n",
    "\n",
    "#We'll clean both training and test data the same way:\n",
    "# Fill missing Age with median\n",
    "train_df['Age'].fillna(train_df['Age'].median(), inplace=True)\n",
    "test_df['Age'].fillna(test_df['Age'].median(), inplace=True)\n",
    "\n",
    "# Fill missing Fare in test set\n",
    "test_df['Fare'].fillna(test_df['Fare'].median(), inplace=True)\n",
    "\n",
    "# Drop 'Cabin' due to too many missing values\n",
    "train_df.drop(columns=['Cabin'], inplace=True)\n",
    "test_df.drop(columns=['Cabin'], inplace=True)\n",
    "\n",
    "# Fill Embarked with mode\n",
    "train_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Convert Sex and Embarked to numeric using one-hot encoding\n",
    "train_df = pd.get_dummies(train_df, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "test_df = pd.get_dummies(test_df, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "\n",
    "# Align columns\n",
    "train_df, test_df = train_df.align(test_df, join='left', axis=1, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbbfb7fc-4c00-46e2-b395-e9d1bc4e3655",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Feature Selection\n",
    "#Choose input features and the target variable:\n",
    "# Drop irrelevant columns\n",
    "X = train_df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Survived'])\n",
    "y = train_df['Survived']\n",
    "\n",
    "# For test data\n",
    "X_test_final = test_df.drop(columns=['PassengerId', 'Name', 'Ticket'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30f5178d-c878-4203-b640-bf284c0735a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8100558659217877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       105\n",
      "           1       0.79      0.74      0.76        74\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.81      0.80      0.80       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#5. Train Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split training data for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "174f2772-f1ae-44e6-9235-7f8a853c667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Survived' in test_df.columns:\n",
    "    test_df = test_df.drop(columns=['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25bde9f4-22bc-4337-9ba8-6acfd6d02340",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = test_df.drop(columns=['PassengerId', 'Name', 'Ticket'])\n",
    "X_test_final = test_df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Survived'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "985daedb-099d-42f6-b79b-8450c5296898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Predict on Test Set\n",
    "# Predict on your test dataset\n",
    "predictions = model.predict(X_test_final)\n",
    "\n",
    "# Create a submission file (if needed for Kaggle)\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "547df897-60d3-480f-8798-99c40e61e7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId\n",
       "0            892\n",
       "1            893\n",
       "2            894\n",
       "3            895\n",
       "4            896\n",
       "..           ...\n",
       "413         1305\n",
       "414         1306\n",
       "415         1307\n",
       "416         1308\n",
       "417         1309\n",
       "\n",
       "[418 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('submission.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34a04434-2d67-41db-90f7-c8d6f748cdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'logistic_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model to a file\n",
    "with open('logistic_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "print(\"Model saved as 'logistic_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1f8f65e-5bf4-4fd3-8ced-0b78ddb4d893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streamlit app file 'streamlit_app.py' created.\n"
     ]
    }
   ],
   "source": [
    "app_code = '''\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained model\n",
    "with open(\"logistic_model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "st.title(\"Logistic Regression Predictor App\")\n",
    "\n",
    "st.write(\"Enter the input features to make a prediction:\")\n",
    "\n",
    "# Example input features (update as per your dataset)\n",
    "# You must match this with your original model features\n",
    "age = st.number_input(\"Age of the car\", min_value=0, value=5)\n",
    "km = st.number_input(\"Kilometers Driven\", min_value=0, value=50000)\n",
    "fuel_diesel = st.selectbox(\"Fuel Type - Diesel?\", [\"No\", \"Yes\"])\n",
    "fuel_petrol = st.selectbox(\"Fuel Type - Petrol?\", [\"No\", \"Yes\"])\n",
    "hp = st.number_input(\"Horse Power\", min_value=0, value=90)\n",
    "automatic = st.selectbox(\"Automatic Transmission?\", [\"No\", \"Yes\"])\n",
    "doors = st.number_input(\"Number of Doors\", min_value=2, max_value=5, value=4)\n",
    "weight = st.number_input(\"Car Weight (kg)\", min_value=500, value=1000)\n",
    "\n",
    "# Convert categorical inputs to binary\n",
    "fuel_diesel = 1 if fuel_diesel == \"Yes\" else 0\n",
    "fuel_petrol = 1 if fuel_petrol == \"Yes\" else 0\n",
    "automatic = 1 if automatic == \"Yes\" else 0\n",
    "\n",
    "# Create input array\n",
    "input_data = np.array([[age, km, fuel_diesel, fuel_petrol, hp, automatic, doors, weight]])\n",
    "\n",
    "# Prediction\n",
    "if st.button(\"Predict\"):\n",
    "    result = model.predict(input_data)\n",
    "    st.success(f\"Prediction: {'Will Purchase' if result[0] == 1 else 'Will Not Purchase'}\")\n",
    "'''\n",
    "\n",
    "# Save to file\n",
    "with open(\"streamlit_app.py\", \"w\") as f:\n",
    "    f.write(app_code)\n",
    "\n",
    "print(\"Streamlit app file 'streamlit_app.py' created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16951d0-0b94-441e-b0dc-9489de2a1926",
   "metadata": {},
   "source": [
    "# Following command needs to be run on the terminal outside the notebook editor:\n",
    "#  streamlit run streamlit_app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d407ae-7617-418a-9098-2d9f3c1ee2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55df0cbf-bc08-48ee-a6f4-241fb0497b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
