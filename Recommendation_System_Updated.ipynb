{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0927866-9970-40ac-87b6-ac61a03cc94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   anime_id                              name  \\\n",
      "0     32281                    Kimi no Na wa.   \n",
      "1      5114  Fullmetal Alchemist: Brotherhood   \n",
      "2     28977                          GintamaÂ°   \n",
      "3      9253                       Steins;Gate   \n",
      "4      9969                     Gintama&#039;   \n",
      "\n",
      "                                               genre   type episodes  rating  \\\n",
      "0               Drama, Romance, School, Supernatural  Movie        1    9.37   \n",
      "1  Action, Adventure, Drama, Fantasy, Magic, Mili...     TV       64    9.26   \n",
      "2  Action, Comedy, Historical, Parody, Samurai, S...     TV       51    9.25   \n",
      "3                                   Sci-Fi, Thriller     TV       24    9.17   \n",
      "4  Action, Comedy, Historical, Parody, Samurai, S...     TV       51    9.16   \n",
      "\n",
      "   members  \n",
      "0   200630  \n",
      "1   793665  \n",
      "2   114262  \n",
      "3   673572  \n",
      "4   151266  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12294 entries, 0 to 12293\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   anime_id  12294 non-null  int64  \n",
      " 1   name      12294 non-null  object \n",
      " 2   genre     12232 non-null  object \n",
      " 3   type      12269 non-null  object \n",
      " 4   episodes  12294 non-null  object \n",
      " 5   rating    12064 non-null  float64\n",
      " 6   members   12294 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 672.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#1. Data Preprocessing\n",
    "#1.1 Load Dataset\n",
    "import pandas as pd\n",
    "\n",
    "anime_df = pd.read_csv('anime.csv')\n",
    "print(anime_df.head())\n",
    "print(anime_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "092a813b-8856-4e3f-95e0-6b014154bebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\APPY\\AppData\\Local\\Temp\\ipykernel_14208\\1164327066.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  anime_df['rating'].fillna(anime_df['rating'].mean(), inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "type\n",
       "TV         3777\n",
       "OVA        3310\n",
       "Movie      2306\n",
       "Special    1674\n",
       "ONA         655\n",
       "Music       488\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.2 Handle Missing Values\n",
    "\n",
    "anime_df.isnull().sum()\n",
    "\n",
    "# Drop or impute\n",
    "anime_df['rating'].fillna(anime_df['rating'].mean(), inplace=True)\n",
    "anime_df.dropna(inplace=True)  # if dropping rows is acceptable\n",
    "\n",
    "#1.3 Explore Dataset\n",
    "\n",
    "anime_df.describe()\n",
    "anime_df['genre'].value_counts()\n",
    "anime_df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "960844f7-0738-41cf-8243-761c083f4783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Feature Extraction\n",
    "#2.1 Encode Categorical Features\n",
    "#Genres: Use multi-label binarizer\n",
    "\n",
    "#Type: One-hot encode\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Split genres into list\n",
    "anime_df['genre'] = anime_df['genre'].apply(lambda x: str(x).split(', '))\n",
    "mlb = MultiLabelBinarizer()\n",
    "genre_encoded = mlb.fit_transform(anime_df['genre'])\n",
    "\n",
    "# Merge back\n",
    "genre_df = pd.DataFrame(genre_encoded, columns=mlb.classes_)\n",
    "anime_features = pd.concat([anime_df[['rating', 'members']], genre_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3f7be46-4524-4608-a52b-56560f56f2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2 Normalize Features\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "anime_scaled = scaler.fit_transform(anime_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17e6dab8-8220-457c-986d-d7cddbf5cec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\APPY\\AppData\\Local\\Temp\\ipykernel_14208\\3644804014.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  anime_df['rating'].fillna(anime_df['rating'].mean(), inplace=True)\n",
      "C:\\Users\\APPY\\AppData\\Local\\Temp\\ipykernel_14208\\3644804014.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  anime_df['members'].fillna(anime_df['members'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "anime_df['rating'].fillna(anime_df['rating'].mean(), inplace=True)\n",
    "anime_df['members'].fillna(anime_df['members'].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1be74225-5bbe-420c-a3da-95fa9b75de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_features = pd.concat([anime_df[['rating', 'members']], genre_df], axis=1)\n",
    "anime_scaled = scaler.fit_transform(anime_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bfe7cc0-3ce3-404e-8360-fd6487aacea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in anime_scaled: 3690\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"NaNs in anime_scaled:\", np.isnan(anime_scaled).sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfc7b373-1c2d-4c14-a616-e7f8b3c8919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_anime(title, top_n=5, threshold=0.5):\n",
    "    index = anime_df[anime_df['name'] == title].index[0]\n",
    "    similarity_scores = list(enumerate(cos_sim[index]))\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    filtered_scores = [i for i in similarity_scores if i[1] >= threshold and i[0] != index]\n",
    "    \n",
    "    top_matches = filtered_scores[:top_n]\n",
    "    recommendations = [anime_df.iloc[i[0]]['name'] for i in top_matches]\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21e5c67d-2da2-4c92-b3d7-0eb85d3c1c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3690"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(anime_scaled).sum()  # should be 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5266225a-d966-4686-952d-a26001d1995f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity matrix computed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Select only numeric features\n",
    "anime_features = anime_df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Handle missing values - fill NaNs with the column mean (or you can choose 0)\n",
    "anime_features = anime_features.fillna(anime_features.mean())\n",
    "\n",
    "# Normalize features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "anime_scaled = scaler.fit_transform(anime_features)\n",
    "\n",
    "# Now safely compute cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cos_sim_matrix = cosine_similarity(anime_scaled)\n",
    "\n",
    "print(\"Cosine similarity matrix computed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a6c6c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Task 2: Evaluation using Precision, Recall, F1-score\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Create dummy binary relevance: top 5 similar anime considered relevant\n",
    "def evaluate_recommendations(sim_matrix, k=5):\n",
    "    precisions, recalls, f1s = [], [], []\n",
    "\n",
    "    for i in range(len(sim_matrix)):\n",
    "        true_indices = np.argsort(sim_matrix[i])[::-1][1:k+1]\n",
    "        predicted_indices = np.argsort(sim_matrix[i])[::-1][1:k+1]\n",
    "\n",
    "        y_true = np.zeros(sim_matrix.shape[0])\n",
    "        y_pred = np.zeros(sim_matrix.shape[0])\n",
    "\n",
    "        y_true[true_indices] = 1\n",
    "        y_pred[predicted_indices] = 1\n",
    "\n",
    "        precisions.append(precision_score(y_true, y_pred))\n",
    "        recalls.append(recall_score(y_true, y_pred))\n",
    "        f1s.append(f1_score(y_true, y_pred))\n",
    "\n",
    "    print(f\"Precision: {np.mean(precisions):.2f}\")\n",
    "    print(f\"Recall: {np.mean(recalls):.2f}\")\n",
    "    print(f\"F1 Score: {np.mean(f1s):.2f}\")\n",
    "\n",
    "evaluate_recommendations(cos_sim_matrix, k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4bca54",
   "metadata": {},
   "source": [
    "\n",
    "### Task 3: Interview Questions\n",
    "\n",
    "**Q1. What is the difference between precision and recall?**\n",
    "\n",
    "- **Precision** is the proportion of true positive predictions among all positive predictions made by the model.  \n",
    "  `Precision = TP / (TP + FP)`\n",
    "\n",
    "- **Recall** is the proportion of true positive predictions among all actual positives.  \n",
    "  `Recall = TP / (TP + FN)`\n",
    "\n",
    "- Precision is useful when false positives are costly.  \n",
    "- Recall is critical when false negatives are more severe.\n",
    "\n",
    "---\n",
    "\n",
    "**Q2. What is cross-validation, and why is it important in binary classification?**\n",
    "\n",
    "- **Cross-validation** is a technique where the data is split into multiple folds, and the model is trained and validated on different combinations of these folds.\n",
    "- It helps assess model performance more reliably by reducing variance caused by a single train-test split.\n",
    "- In **binary classification**, it ensures the model generalizes well to unseen data and helps avoid overfitting.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
